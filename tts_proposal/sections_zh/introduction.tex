\section*{引言}

人工智能（AI）的快速发展推动了语音技术领域的显著增长，影响着从娱乐到无障碍的各个行业。对于自然且情感丰富的文本转语音 (TTS) 系统的需求日益增长，这由诸如有声读物、音频剧和互动体验等应用驱动。尽管当前最先进的神经 TTS 模型在英语中表现出色，但在应用于其他语言，特别是资源匮乏的语言（如孟加拉语和中文）时，却面临着巨大的挑战。这些挑战源于语言特定韵律（语调、节奏、重音）和声调变化的复杂性。因此，合成的语音往往缺乏人类声音的情感表达和细微的韵律特征，呈现出机械的品质。\newline

尽管现有的 TTS 模型能够生成可理解的语音，但它们通常难以捕捉人类情感和韵律细微差异的全部范围。这种限制在资源匮乏的语言中尤其严重，因为这些语言的训练数据有限，而且韵律模式也具有独特的特征。此外，控制合成语音中的年龄、性别和情感表达等属性仍然是一个巨大的障碍。这限制了 TTS 的实际应用，使其无法超越基本的转录任务。\newline

本研究旨在开发一个可投入产业应用的多语言 TTS 框架，通过为英语、孟加拉语和中文生成逼真的人声来应对这些限制。该框架将侧重于创建高质量的合成语音，并控制包括年龄、性别和情感表达在内的属性。关键部分是开发能够处理每种语言特定韵律和声调特征的鲁棒模型，特别是孟加拉语和中文的独特特征。这包括解决孟加拉语数据稀缺问题以及改进所有三种语言的韵律建模技术。最终系统将提高合成语音的质量和自然度，从而在更广泛的应用中创建更引人入胜和令人信服的内容。\newline

除了增强讲故事和娱乐功能，该框架还适用于辅助技术、虚拟助手、人工智能驱动的客户服务和教育工具。能够将语音调整为各种情绪状态和说话人特征，将能够在不同的语言和文化背景下提供身临其境的互动体验，从而推动生成语音应用的可能性边界。